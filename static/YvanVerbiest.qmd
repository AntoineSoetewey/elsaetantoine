---
title: "Mémoire"
# subtitle: "Sous-titre"
author: "Yvan Verbiest"
date: "`r Sys.Date()`"
editor: visual
# abstract: "abstract"
# format:
#   pdf:
#     toc: true
#     # toc-depth: 6
#     number-sections: true
format:
  html:
    toc: true
    # toc-depth: 6
    number-sections: true
    code-fold: true
    code-tools: true
    # theme: flatly
    # highlight-style: tango
    self-contained: true
    citations-hover: true
    citation-location: margin
# format:
#   docx:
#     toc: true
#     number-sections: true
execute:
  # echo: false # uncomment if output is word
  warning: false
lang: fr
bibliography: bibliography.bib
---

```{r}
#| label: load-packages
#| include: false

# options(scipen=999)

# Package names
# packages <- c("ggplot2", "dplyr", "tidyr", "ggfortify", "DT", "reshape2", "knitr", "lubridate", "pwr", "psy", "car", "doBy", "imputeMissings", "questionr", "vcd", "multcomp", "KappaGUI", "rcompanion", "FactoMineR", "factoextra", "corrplot", "ltm", "goeveg", "corrplot", "FSA", "MASS", "scales", "nlme", "psych", "ordinal", "lmtest", "ggpubr", "dslabs", "stringr", "assist", "ggstatsplot", "forcats", "styler", "remedy", "addinslist", "esquisse", "here", "summarytools", "magrittr", "tidyverse", "funModeling", "pander", "cluster", "rstatix", "finalfit", "visreg", "performance", "snakecase")

packages <- c("ggplot2", "dplyr", "tidyr", "tidyverse", "ggstatsplot", "pander")

# Install packages not yet installed
# installed_packages <- packages %in% rownames(installed.packages())
# if (any(installed_packages == FALSE)) {
#   install.packages(packages[!installed_packages])
# }

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

theme_set(theme_minimal())

set.seed(42)
```

# Résumé des tests statistiques pour comparaison de groupes ou temps

Pour rappel, ci-dessous un tableau récapitulatif reprenant les différents tests statistiques utilisés pour comparer deux groupes/temps ou plus, ainsi que les cas dans lesquels ils sont utilisés :

| Comparaison entre              | Type             | Test                                  |
|------------------------|------------------|------------------------------|
| 2 groupes indépendants         | Paramétrique     | Test de Student (aussi appelé t-test) |
| 2 groupes indépendants         | Non-paramétrique | Test de Mann-Whitney                  |
| 2 groupes dépendants           | Paramétrique     | Test de Student pour données pairées  |
| 2 groupes dépendants           | Non-paramétrique | Test de Wilcoxon pour données pairées |
| Plus de 2 groupes indépendants | Paramétrique     | ANOVA                                 |
| Plus de 2 groupes indépendants | Non-paramétrique | Kruskal-Wallis                        |
| Plus de 2 groupes dépendants   | Paramétrique     | ANOVA à mesures répétées              |
| Plus de 2 groupes dépendants   | Non-paramétrique | Friedman test                         |

Notons que les tests paramétriques sont utilisés pour des grands échantillons (à partir de 30 observations par groupe, grâce au théorème central limite) et les tests non-paramétriques sont utilisés pour les petits échantillons [@ghasemi2012normality].

Voir cet [arbre décisionnel](https://statsandr.com/blog/files/overview-statistical-tests-statsandr.pdf) pour un récapitulatif plus détaillé des différents tests statistiques en fonction du type de variable.

# Comparaison du RE entre les 2 rotations (RE et RI)

Dans ce qui suit, nous comparons la colonne RE entre les 2 rotations (RE et RI). Etant donné que les patients sont mesurés 2 fois (pour RE et pour RI), nous avons des échantillons **dépendants**. De plus, nous avons une grande taille d'échantillon, nous utilisons donc le test de Student pour données pairées.

Nous faisons un boxplot pour représenter visuellement les données et nous appliquons ce test.

Un boxplot (appelé aussi boîte à moustaches) permet de visualiser les données. Notons que la ligne grasse dans la boîte représente la médiane (i.e., la valeur qui divise en deux parts égales les données, c'est-à-dire qu'il y a 50% des observations en-dessous de cette valeur et 50% au-dessus de cette valeur). Des boxplots qui se trouvent à la même hauteur laisse supposer que les groupes ne sont pas différents. Au contraire, des boxplots qui se trouvent à des hauteurs radicalement différentes laisse supposer que les groupes sont différents. Cependant, seul un test statistique permet d'appliquer ces suppositions faites depuis le graphique sur la population.

La $p$-valeur du test est affichée au-dessus du graphique (c'est la valeur qui se trouve après `p =`, les autres valeurs sont moins intéressantes dans le cadre de ton mémoire). Pour rappel, une $p$-valeur en-dessous du seuil de significativité $\alpha$ = 0.05 (i.e., $p$-value \< 0.05) signifie qu'on rejette l'hypothèse nulle, tandis qu'une $p$-valeur égale ou au-dessus de ce seuil de significativité $\alpha$ = 0.05 (i.e., $p$-value $\ge$ 0.05) signifie qu'on ne rejette pas l'hypothèse nulle. Enfin, voici l'hypothèse nulle et l'hypothèse alternative du test :

-   $H_0$: pas de différence significative
-   $H_1$: différence significative

Les résultats impliquent que si l'on rejette l'hypothèse nulle (parce que la $p$-valeur \< 0.05), on peut considérer que les distributions sont significativement différentes, tandis que si l'on ne rejette pas l'hypothèse nulle (parce que la $p$-valeur $\geq$ 0.05), ceci implique que les données ne nous permettent pas de rejeter le fait que les distributions sont les mêmes et on ne peut donc pas conclure à une différence significative.

```{r}
#| eval: true
dat <- read.csv(paste0("data/", "dat1.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

# View(dat)
# str(dat)

# to edit #
x <- "rotation"
start_y <- 2
paired <- TRUE
# to edit #

type <- ifelse(
  min(table(dat[, x])) < 30,
  "nonparametric",
  "parametric"
)

plotlist <-
  purrr::pmap(
    .l = list(
      data = list(as_tibble(dat)),
      x = x,
      # y = list("Var1", "Var2", "Var3"),
      y = as.list(colnames(dat)[start_y:ncol(dat)]),
      plot.type = "box",
      type = type,
      pairwise.comparisons = TRUE,
      pairwise.display = "significant",
      bf.message = FALSE,
      # nboot = 1L,
      centrality.plotting = FALSE
    ),
    .f = ifelse(paired,
                ggstatsplot::ggwithinstats,
                ggstatsplot::ggbetweenstats)
  )

for (i in 1:length(plotlist)) {
  print(plotlist[[i]] + labs(caption = NULL))
}
```

**Interprétations statistiques**

Sur base des résultats du test :

-   On ne rejette pas l'hypothèse nulle, donc on ne rejette pas l'hypothèse que RE est égal entre les 2 rotations RE et R1 ($p$-value = 0.645).

# Comparaison du score composite entre les 3 types (medial, inferolat et superolat)

Dans ce qui suit, nous comparons les 3 types d'abord pour le bras dominant (colonnes AZ, BA, BB), et ensuite pour les bras non dominant (colonnes BC, BD, BE). Etant donné que les mesures pour les 3 types ont été faites pour les mêmes patients, nous avons des échantillons **dépendants**. De plus, nous avons une grande taille d'échantillon, nous utilisons donc une ANOVA à mesures répétées.

Ici aussi nous faisons un boxplot pour représenter visuellement les données et nous appliquons ce test, dont voici les hypothèses :

-   $H_0$: pas de différence significative
-   $H_1$: différence significative pour au moins 1 type

Les résultats impliquent que si l'on rejette l'hypothèse nulle (parce que la $p$-valeur \< 0.05), on peut considérer qu'il y ait au moins une distribution (et donc un type) différente des autres. En effet, le rejet de l'hypothèse nulle ne veut pas dire que tous les types sont différents, un seul différent des autres suffit pour rejeter l'hypothèse nulle. Au contraire, si l'on ne rejette pas l'hypothèse nulle (parce que la $p$-valeur $\ge$ 0.05), ceci implique que les données ne nous permettent pas de rejeter le fait que les distributions sont les mêmes et on ne peut donc pas rejeter le fait que tous les types sont égaux.

<!-- Remove if p-value of anova or kruskal wallis > 0.05 -->

Cependant, il faut noter que même si le test permet de déterminer s'il y a au moins un type différent des autres ou non, cela ne permet pas de conclure **lesquels** sont différents l'un de l'autre s'il y en a au moins un différent des autres. Pour cela, il existe des tests post-hoc qui permettent de comparer tous les types deux par deux pour déterminer lesquels diffèrent. Les $p$-valeurs de ces comparaisons 2 à 2 (après ajustement de la $p$-valeur pour les comparaisons multiples) sont également affichées dans le graphique via des accolades **dans le cas où au moins un type est différent d'un autre** (donc si on ne rejette pas l'hypothèse que tous les types sont égaux, on ne fait pas de test post-hoc, et les accolades ne sont donc pas présentes).

Concrètement, les $p$-valeurs sur les accolade sont les $p$-valeurs des tests de comparaisons multiples, et ce pour chaque paire de types possible. L'hypothèse nulle est que les deux types sont égaux, l'hypothèse alternative est qu'ils sont différents. Donc si la $p$-valeur de l'accolade est \< 0.05, cela signifie qu'au seuil de significativité $\alpha$ = 0.05, nous rejetons l'hypothèse nulle et on peut donc conclure que les deux types sont différents. Par contre, si la $p$-valeur de l'accolade est $\ge$ 0.05, cela signifie (toujours au seuil de significativité $\alpha$ = 0.05) que nous ne rejetons pas l'hypothèse nulle et on ne peut donc pas rejeter le fait que les 2 types sont égaux.

## Bras dominant

```{r}
#| eval: true
dat_all <- read.csv(paste0("data/", "dat2.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

dat <- subset(dat_all, bras == "dominant")

# View(dat)
# str(dat)

# to edit #
x <- "type"
start_y <- 3
paired <- TRUE
# to edit #

type <- ifelse(
  min(table(dat[, x])) < 30,
  "nonparametric",
  "parametric"
)

plotlist <-
  purrr::pmap(
    .l = list(
      data = list(as_tibble(dat)),
      x = x,
      # y = list("Var1", "Var2", "Var3"),
      y = as.list(colnames(dat)[start_y:ncol(dat)]),
      plot.type = "box",
      type = type,
      pairwise.comparisons = TRUE,
      pairwise.display = "significant",
      bf.message = FALSE,
      # nboot = 1L,
      centrality.plotting = FALSE
    ),
    .f = ifelse(paired,
                ggstatsplot::ggwithinstats,
                ggstatsplot::ggbetweenstats)
  )

for (i in 1:length(plotlist)) {
  print(plotlist[[i]] + labs(caption = NULL))
}
```

**Interprétations statistiques**

Sur base des résultats des tests, le score composite est significativement différent entre :

-   inferolat et medial ($p$-valeur \< 0.001)
-   inferolat et superolat ($p$-valeur \< 0.001)
-   superolat et medial ($p$-valeur \< 0.001)

De plus, au vu de la hauteur des boxplots, on peut conclure que le score composite est le plus élevé pour medial, et le plus bas pour superolat.

## Bras non dominant

```{r}
#| eval: true
dat_all <- read.csv(paste0("data/", "dat2.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

dat <- subset(dat_all, bras == "non dominant")

# View(dat)
# str(dat)

# to edit #
x <- "type"
start_y <- 3
paired <- TRUE
# to edit #

type <- ifelse(
  min(table(dat[, x])) < 30,
  "nonparametric",
  "parametric"
)

plotlist <-
  purrr::pmap(
    .l = list(
      data = list(as_tibble(dat)),
      x = x,
      # y = list("Var1", "Var2", "Var3"),
      y = as.list(colnames(dat)[start_y:ncol(dat)]),
      plot.type = "box",
      type = type,
      pairwise.comparisons = TRUE,
      pairwise.display = "significant",
      bf.message = FALSE,
      # nboot = 1L,
      centrality.plotting = FALSE
    ),
    .f = ifelse(paired,
                ggstatsplot::ggwithinstats,
                ggstatsplot::ggbetweenstats)
  )

for (i in 1:length(plotlist)) {
  print(plotlist[[i]] + labs(caption = NULL))
}
```

**Interprétations statistiques**

Sur base des résultats des tests, le score composite est significativement différent entre :

-   inferolat et medial ($p$-valeur \< 0.001)
-   inferolat et superolat ($p$-valeur \< 0.001)
-   superolat et medial ($p$-valeur \< 0.001)

De plus, au vu de la hauteur des boxplots, on peut conclure que le score composite est le plus élevé pour medial, et le plus bas pour superolat.

# Comparaison du score composite entre bras dominant et non dominant

Dans cette section, nous comparons le score composite entre le bras dominant et le bras non dominant. Comme ce sont à nouveau des mesures prises sur les mêmes patients, nous avons des échantillons dépendants. Comme la taille d'échantillon est grande, nous utilisons le test de Student pour données pairées.

Pour rappel, voici les hypothèses du test :

-   $H_0$: pas de différence significative
-   $H_1$: différence significative

C'est en fait le même test que pour la section 2, vu qu'on comparais aussi 2 échantillons pairés de grandes tailles.

```{r}
#| eval: true
dat <- read.csv(paste0("data/", "dat3.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

# View(dat)
# str(dat)

# to edit #
x <- "bras"
start_y <- 2
paired <- TRUE
# to edit #

type <- ifelse(
  min(table(dat[, x])) < 30,
  "nonparametric",
  "parametric"
)

plotlist <-
  purrr::pmap(
    .l = list(
      data = list(as_tibble(dat)),
      x = x,
      # y = list("Var1", "Var2", "Var3"),
      y = as.list(colnames(dat)[start_y:ncol(dat)]),
      plot.type = "box",
      type = type,
      pairwise.comparisons = TRUE,
      pairwise.display = "significant",
      bf.message = FALSE,
      # nboot = 1L,
      centrality.plotting = FALSE
    ),
    .f = ifelse(paired,
                ggstatsplot::ggwithinstats,
                ggstatsplot::ggbetweenstats)
  )

for (i in 1:length(plotlist)) {
  print(plotlist[[i]] + labs(caption = NULL))
}
```

**Interprétations statistiques**

Sur base des résultats du test :

-   On rejette l'hypothèse nulle, et on conclut que le score composite est différent entre le bras dominant et le bras non dominant ($p$-value = 0.002).

# Corrélations des scores composites avec RE

Dans cette section, on teste s'il existe un lien linéaire significatif entre la variable RE et les scores composites grâce à un test de corrélation. Nous faisons cela de manière séparée pour RE et RI.

Pour rappel, la corrélation est une mesure statistique qui permet de mesurer le lien linéaire entre 2 variables quantitatives (ou 2 variables qualitatives ordinales). De plus, le *test* de corrélation permet de tester s'il existe un lien entre les 2 variables dans la population. Pour rappel, les hypothèses pour le test de corrélation sont les suivantes:

-   $H_0$: corrélation $\rho = 0$
-   $H_1$: corrélation $\rho \ne 0$

Notez que nous utilisons le coefficient de corrélation de Pearson car nous avons à chaque fois 2 variables quantitatives.

A noter que dans le tableau ci-dessous la colonne `r` correspond au coefficient de corrélation entre les 2 variables, et que la colonne `p` correspond à la $p$-valeur du test de corrélation. Pour rappel, voici comment interpréter le test de corrélation :

-   Si la $p$-valeur \< 0.05, on rejette l'hypothèse nulle et on conclut donc à une corrélation significativement différente de 0 entre les 2 variables. Il suffit alors de regarder le coefficient de corrélation pour savoir si le lien entre les 2 variables est positif (les 2 variables varient dans le même sens) ou négatif (les 2 variables varient dans des sens opposés).
-   Si la $p$-valeur $\ge$ 0.05, on ne rejette pas l'hypothèse nulle et donc on ne conclut pas à une corrélation significativement différente de 0 entre les 2 variables. Ceci veut dire que les données ne nous permettent pas de mettre en évidence un lien linéaire entre les 2 variables.

## Pour RE

```{r}
dat_all <- read.csv(paste0("data/", "dat4.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

dat <- subset(dat_all, rotation == "RE")

# Pearson
res <- as.data.frame(correlation::correlation(dat[, 2:10], method = "pearson", p_adjust = "none")[1:8, c(1:3, 9, 11)])

res$Conclusion <- ifelse(res$p < 0.05, "Rejet H0", "Non-rejet H0")

pander(res)
```

**Interprétations statistiques**

Sur base des résultats des tests :

-   On conclut qu'il existe une corrélation significative entre RE et :
    -   score_composite_bras_non_dominant ($p$-valeur = 0.01). Au vu du coefficient qui est négatif, le lien entre les 2 variables est négatif.
    -   score_composite_inferolat_bras_non_dominant ($p$-valeur = 0.03). Au vu du coefficient qui est négatif, le lien entre les 2 variables est négatif.
    -   score_composite_superolat_bras_non_dominant ($p$-valeur = 0.006). Au vu du coefficient qui est négatif, le lien entre les 2 variables est négatif.
-   On ne rejette pas l'hypothèse qu'il n'y a pas de lien linéaire entre RE et :
    -   score_composite_bras_dominant ($p$-valeur = 0.23)
    -   score_composite_medial_bras_dominant ($p$-valeur = 0.52)
    -   score_composite_inferolat_bras_dominant ($p$-valeur = 0.55)
    -   score_composite_superolat_bras_dominant ($p$-valeur = 0.077)
    -   score_composite_medial_bras_non_dominant ($p$-valeur = 0.14)
    
Visuellement pour les corrélations significativement différentes de 0, nous avons:

```{r}
ggscatterstats(
  data = dat,
  x = non_dominant,
  y = RE,
  bf.message = FALSE
)
ggscatterstats(
  data = dat,
  x = inferolat_non_dominant,
  y = RE,
  bf.message = FALSE
)
ggscatterstats(
  data = dat,
  x = superolat_non_dominant,
  y = RE,
  bf.message = FALSE
)
```

## Pour RI

```{r}
dat_all <- read.csv(paste0("data/", "dat4.csv"),
  header = TRUE,
  sep = ",",
  dec = ".",
  stringsAsFactors = TRUE
  # , na.strings = c("", " ", "NA")
)

dat <- subset(dat_all, rotation == "RI")

# Pearson
res <- as.data.frame(correlation::correlation(dat[, 2:10], method = "pearson", p_adjust = "none")[1:8, c(1:3, 9, 11)])

res$Conclusion <- ifelse(res$p < 0.05, "Rejet H0", "Non-rejet H0")

pander(res)
```

**Interprétations statistiques**

Sur base des résultats des tests :

-   On conclut qu'il existe une corrélation significative entre RE et :
    -   score_composite_medial_bras_dominant ($p$-valeur = 0.006). Au vu du coefficient qui est négatif, le lien entre les 2 variables est négatif.
    -   score_composite_medial_bras_non_dominant ($p$-valeur = 0.012). Au vu du coefficient qui est négatif, le lien entre les 2 variables est négatif.
-   On ne rejette pas l'hypothèse qu'il n'y a pas de lien linéaire entre RE et :
    -   score_composite_bras_dominant ($p$-valeur = 0.13)
    -   score_composite_bras_non_dominant ($p$-valeur = 0.41)
    -   score_composite_inferolat_bras_dominant ($p$-valeur = 0.075)
    -   score_composite_superolat_bras_dominant ($p$-valeur = 0.60)
    -   score_composite_inferolat_bras_non_dominant ($p$-valeur = 0.37)
    -   score_composite_medial_bras_non_dominant ($p$-valeur = 0.34)
    
  Visuellement pour les corrélations significativement différentes de 0, nous avons:

```{r}
ggscatterstats(
  data = dat,
  x = medial_dominant,
  y = RE,
  bf.message = FALSE
)
ggscatterstats(
  data = dat,
  x = medial_non_dominant,
  y = RE,
  bf.message = FALSE
)
```

# Ressources supplémentaires

Ci-dessous des ressources supplémentaires (en anglais) qui aideront à mieux comprendre les analyses faites dans ce travail:

-   [Quel test statistique dois-je faire ?](https://statsandr.com/blog/what-statistical-test-should-i-do/)
-   [Coefficient de corrélation et test de corrélation](https://statsandr.com/blog/correlation-coefficient-and-correlation-test-in-r/)
-   [Test de Student](https://statsandr.com/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/)
-   [ANOVA pour comparer plus de 2 groupes](https://statsandr.com/blog/anova-in-r/)

# Programme

Tous les graphiques et analyses ont été faits sur le programme `r version$version.string`.
